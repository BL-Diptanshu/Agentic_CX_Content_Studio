2026-02-06 10:21:42 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 10:21:42 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 10:23:29 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 10:23:29 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 10:24:47 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 10:24:47 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 13:43:49 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: GET http://testserver/api/v1/health "HTTP/1.1 200 OK"
2026-02-06 13:43:49 - src.routes.api_routes - INFO - [api_routes.py:35] - create_campaign() - Creating campaign: API Test Campaign for brand: API Brand
2026-02-06 13:43:49 - src.routes.api_routes - INFO - [api_routes.py:46] - create_campaign() - Campaign created successfully: ID=1
2026-02-06 13:43:49 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: POST http://testserver/api/v1/start_campaign "HTTP/1.1 200 OK"
2026-02-06 13:43:49 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: GET http://testserver/api/v1/campaigns/99999 "HTTP/1.1 404 Not Found"
2026-02-06 13:43:49 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: POST http://testserver/api/v1/generate/text "HTTP/1.1 500 Internal Server Error"
2026-02-06 13:43:50 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: POST http://testserver/api/v1/validate/text "HTTP/1.1 500 Internal Server Error"
2026-02-06 13:43:59 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 13:43:59 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 13:44:58 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: GET http://testserver/api/v1/health "HTTP/1.1 200 OK"
2026-02-06 13:44:58 - src.routes.api_routes - INFO - [api_routes.py:35] - create_campaign() - Creating campaign: API Test Campaign for brand: API Brand
2026-02-06 13:44:58 - src.routes.api_routes - INFO - [api_routes.py:46] - create_campaign() - Campaign created successfully: ID=1
2026-02-06 13:44:58 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: POST http://testserver/api/v1/start_campaign "HTTP/1.1 200 OK"
2026-02-06 13:44:58 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: GET http://testserver/api/v1/campaigns/99999 "HTTP/1.1 404 Not Found"
2026-02-06 13:44:58 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: POST http://testserver/api/v1/generate/text "HTTP/1.1 200 OK"
2026-02-06 13:44:58 - httpx - INFO - [_client.py:1025] - _send_single_request() - HTTP Request: POST http://testserver/api/v1/validate/text "HTTP/1.1 200 OK"
2026-02-06 13:45:03 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 13:45:03 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 14:42:43 - src.core.brand_kb_loader - INFO - [brand_kb_loader.py:19] - __init__() - Initialized BrandKBLoader with path: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\forbidden_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:31] - load_forbidden_language() - Loaded 0 forbidden language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:83] - get_all_forbidden_terms() - Total forbidden terms: 0
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\policy\allowed_language.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:43] - load_allowed_language() - Loaded 0 allowed language categories
2026-02-06 14:42:43 - src.core.brand_kb_loader - WARNING - [brand_kb_loader.py:129] - _load_json() - KB file not found: C:\Users\ASUS\AppData\Local\Temp\pytest-of-ASUS\pytest-0\test_validator_initialization0\brand_kb\tone\tone_profile.json
2026-02-06 14:42:43 - src.core.brand_kb_loader - DEBUG - [brand_kb_loader.py:55] - load_tone_profile() - Loaded tone profile with 0 sections
2026-02-06 14:42:43 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 0 forbidden terms, 0 allowed phrases
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.00ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.00ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 14:42:43 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:45 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: Replicate API Error
2026-02-06 14:42:45 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:45 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.54ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 14:42:45 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:45 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: Replicate returned empty output.
2026-02-06 14:42:45 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 14:42:45 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 1.51ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Create marketing copy...'
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 41 characters in 1.52ms
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-70b-versatile
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test prompt...'
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 41 characters in 1.00ms
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test...'
2026-02-06 14:42:45 - src.core.text_content_gen - ERROR - [text_content_gen.py:106] - generate_text() - Text generation failed: Run with UUID b2dcc8ff71ee412caec567daf7e894b7 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 14:42:45 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test...'
2026-02-06 14:42:45 - src.core.text_content_gen - ERROR - [text_content_gen.py:106] - generate_text() - Text generation failed: Run with UUID b2dcc8ff71ee412caec567daf7e894b7 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-06 15:13:33 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:33 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:33 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.97ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 15:13:33 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:33 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.00ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 15:13:33 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:34 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: Replicate API Error
2026-02-06 15:13:34 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:34 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.00ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 15:13:34 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:35 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: Replicate returned empty output.
2026-02-06 15:13:35 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 15:13:35 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.56ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Create marketing copy...'
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 41 characters in 3.54ms
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-70b-versatile
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test prompt...'
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 41 characters in 0.00ms
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test...'
2026-02-06 15:13:35 - src.core.text_content_gen - ERROR - [text_content_gen.py:106] - generate_text() - Text generation failed: Run with UUID e61e80733b1a4bb8859258e55f28fbbe is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 15:13:35 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test...'
2026-02-06 15:13:35 - src.core.text_content_gen - ERROR - [text_content_gen.py:106] - generate_text() - Text generation failed: Run with UUID e61e80733b1a4bb8859258e55f28fbbe is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2026-02-06 16:53:01 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 16:53:01 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 16:53:01 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 16:53:01 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 16:53:08 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 16:53:08 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 16:53:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 16:53:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 16:53:09 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 16:53:09 - src.core.orchestrator - INFO - [orchestrator.py:133] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 16:53:09 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 16:53:09 - src.core.orchestrator - INFO - [orchestrator.py:137] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 16:53:09 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 16:53:09 - src.core.orchestrator - INFO - [orchestrator.py:101] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 16:53:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:53:09 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:53:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:53:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:53:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:53:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:53:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:53:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:53:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:53:11 - src.core.orchestrator - ERROR - [orchestrator.py:107] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_guideline_retriever({\"k\": 1, \"query\": \"What is the visual identity for FitNow?\"})\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_guideline_retriever({\"k\": 1, \"query\": \"What is the visual identity for FitNow?\"})\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 102, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_guideline_retriever({\"k\": 1, \"query\": \"What is the visual identity for FitNow?\"})\u003c/function\u003e"}}

2026-02-06 16:53:53 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x16680e74e10>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 16:56:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 16:56:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 16:56:03 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 16:56:03 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 16:56:08 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 16:56:08 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 16:56:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 16:56:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 16:56:09 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 16:56:09 - src.core.orchestrator - INFO - [orchestrator.py:133] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 16:56:09 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 16:56:09 - src.core.orchestrator - INFO - [orchestrator.py:137] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 16:56:09 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 16:56:09 - src.core.orchestrator - INFO - [orchestrator.py:101] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 16:56:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:56:09 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:56:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:56:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:56:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:56:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 16:56:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:12 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 16:56:12 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 16:56:12 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Embrace the FitNow New Year Wellness Journey, wher...'
2026-02-06 16:56:13 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2046 characters in 1173.78ms
2026-02-06 16:56:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 16:56:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:56:14 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 16:56:14 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 16:56:14 - src.core.orchestrator - INFO - [orchestrator.py:148] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 16:56:55 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x2e7f2e88c10>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 16:57:42 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x2e7f2f12390>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 16:58:11 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 16:58:11 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 16:58:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 16:58:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 16:58:12 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 16:58:12 - src.core.orchestrator - INFO - [orchestrator.py:133] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 16:58:12 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 16:58:12 - src.core.orchestrator - INFO - [orchestrator.py:137] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 16:58:12 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 16:58:12 - src.core.orchestrator - INFO - [orchestrator.py:101] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 16:58:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:13 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 16:58:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:15 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Embracing a wellness journey with FitNow means foc...'
2026-02-06 16:58:15 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1154 characters in 552.28ms
2026-02-06 16:58:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 16:58:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:16 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 16:58:16 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 16:58:16 - src.core.orchestrator - INFO - [orchestrator.py:148] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 16:58:25 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 16:58:25 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 16:58:25 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 16:58:25 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 16:58:25 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 16:58:25 - src.core.orchestrator - INFO - [orchestrator.py:133] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 16:58:25 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 16:58:25 - src.core.orchestrator - INFO - [orchestrator.py:137] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 16:58:25 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 16:58:25 - src.core.orchestrator - INFO - [orchestrator.py:101] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 16:58:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:25 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:27 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 16:58:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:27 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 16:58:28 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:28 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Embracing the innovative and approachable attribut...'
2026-02-06 16:58:29 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2471 characters in 987.68ms
2026-02-06 16:58:29 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 16:58:30 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 16:58:30 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 16:58:30 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 16:58:30 - src.core.orchestrator - INFO - [orchestrator.py:148] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 16:58:54 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x2e7f2e890d0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 16:59:41 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x2e7f2fe0750>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:01:13 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:01:13 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:01:13 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:01:13 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:01:18 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:01:18 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:01:19 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:01:19 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:01:19 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:01:19 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:01:19 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:01:19 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:01:19 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:01:19 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:01:19 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:21 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:21 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:21 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:22 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:22 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:23 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:01:23 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:01:23 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11358, Requested 880. Please try again in 1.19s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11358, Requested 880. Please try again in 1.19s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11358, Requested 880. Please try again in 1.19s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:02:05 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x20d6c35b010>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:02:52 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x20d80f46190>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:07:44 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:07:44 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:07:44 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:07:44 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:07:48 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:07:48 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:07:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:07:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:07:49 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:07:49 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:07:49 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:07:49 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:07:49 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:07:49 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:07:49 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:49 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:07:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 17:07:53 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11859, Requested 1254. Please try again in 5.564999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11859, Requested 1254. Please try again in 5.564999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 12000, Used 11859, Requested 1254. Please try again in 5.564999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:08:36 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1c849cd0ed0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:09:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:09:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:09:03 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:09:03 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:09:08 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:09:08 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:09:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:09:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:09:08 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:09:08 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:09:08 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:09:08 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:09:08 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:09:08 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:09:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:12 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 17:09:12 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 17:09:12 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Based on the retrieved brand voice, tone, and guid...'
2026-02-06 17:09:14 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2526 characters in 1521.34ms
2026-02-06 17:09:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:14 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4943, Requested 1631. Please try again in 5.74s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4943, Requested 1631. Please try again in 5.74s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4943, Requested 1631. Please try again in 5.74s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:09:41 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:09:41 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:09:41 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:09:41 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:09:41 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:09:41 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:09:41 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:09:41 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:09:41 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:09:41 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:09:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:43 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:43 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:43 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:43 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:43 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:09:43 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:09:44 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brand_forbidden_words_checker' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_forbidden_words_checker\u003e{\"content\":\"Check campaign plan strategy for forbidden words\"}\u003c/function\u003e\n\n"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'brand_forbidden_words_checker' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_forbidden_words_checker\u003e{\"content\":\"Check campaign plan strategy for forbidden words\"}\u003c/function\u003e\n\n"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brand_forbidden_words_checker' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_forbidden_words_checker\u003e{\"content\":\"Check campaign plan strategy for forbidden words\"}\u003c/function\u003e\n\n"}}

2026-02-06 17:09:55 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x212a266ab50>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:10:42 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x21302dc8890>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:11:46 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:11:46 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:11:46 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:11:46 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:11:50 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:11:50 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:11:50 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:11:50 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:11:51 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:11:51 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:11:51 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:11:51 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:11:51 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:11:51 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:11:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:11:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:11:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:11:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:11:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:11:54 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 17:11:54 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 17:11:54 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write a compelling marketing copy for a wellness c...'
2026-02-06 17:11:55 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2137 characters in 978.60ms
2026-02-06 17:11:55 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:11:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:11:56 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4612, Requested 1460. Please try again in 720ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4612, Requested 1460. Please try again in 720ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4612, Requested 1460. Please try again in 720ms. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:12:33 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x23f839ade50>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:13:24 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:13:24 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:13:25 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:13:25 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:13:29 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:13:29 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:13:29 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:13:29 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:13:29 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:13:29 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:13:29 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:13:29 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:13:29 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:13:29 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:13:29 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:13:31 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:13:31 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:13:31 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:13:31 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:13:31 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'get_target_audience' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"In order to determine the required information to validate the campaign plan, we need to determine the target audience, forbidden language/terms and messaging framework. \n\n\u003cfunction=get_target_audience\u003e{\"product_category\": \"Electronics\", \"geo_target\": \"Europe\"} \u003c/function\u003e\n"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'get_target_audience' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"In order to determine the required information to validate the campaign plan, we need to determine the target audience, forbidden language/terms and messaging framework. \n\n\u003cfunction=get_target_audience\u003e{\"product_category\": \"Electronics\", \"geo_target\": \"Europe\"} \u003c/function\u003e\n"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'get_target_audience' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"In order to determine the required information to validate the campaign plan, we need to determine the target audience, forbidden language/terms and messaging framework. \n\n\u003cfunction=get_target_audience\u003e{\"product_category\": \"Electronics\", \"geo_target\": \"Europe\"} \u003c/function\u003e\n"}}

2026-02-06 17:14:11 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x15e51e729d0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:14:58 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x15e807fe610>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:16:48 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:16:48 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:16:49 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:16:49 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:16:54 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:16:54 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:16:54 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:16:54 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:16:54 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:16:54 - src.core.orchestrator - INFO - [orchestrator.py:145] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:16:54 - src.core.orchestrator - INFO - [orchestrator.py:146] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:16:54 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:16:54 - src.core.orchestrator - INFO - [orchestrator.py:42] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:16:54 - src.core.orchestrator - INFO - [orchestrator.py:113] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:16:54 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:16:55 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:16:55 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:16:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:16:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:16:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:16:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:16:58 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:16:59 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 17:16:59 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 17:16:59 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Reflect the brand voice by speaking about the futu...'
2026-02-06 17:17:00 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1991 characters in 1060.05ms
2026-02-06 17:17:00 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:17:00 - src.core.orchestrator - ERROR - [orchestrator.py:119] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4675, Requested 2006. Please try again in 6.81s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4675, Requested 2006. Please try again in 6.81s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 114, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4675, Requested 2006. Please try again in 6.81s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:17:41 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1e7c3c34890>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:18:28 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1e804f537d0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:20:13 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:20:13 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:20:13 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:20:13 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:20:19 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:20:19 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:20:19 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:20:19 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:20:19 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:20:19 - src.core.orchestrator - INFO - [orchestrator.py:164] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:20:19 - src.core.orchestrator - INFO - [orchestrator.py:165] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:20:19 - src.core.orchestrator - INFO - [orchestrator.py:168] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:20:19 - src.core.orchestrator - INFO - [orchestrator.py:61] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:20:19 - src.core.orchestrator - INFO - [orchestrator.py:132] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:20:19 - src.core.orchestrator - ERROR - [orchestrator.py:138] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model={'model': 'groq/llama-3.1-8b-instant', 'max_tokens': 500, 'temperature': 0.7}
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 133, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 308, in _invoke_loop
    return self._invoke_loop_react()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 429, in _invoke_loop_react
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 337, in _invoke_loop_react
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 1306, in completion
    model, custom_llm_provider, dynamic_api_key, api_base = get_llm_provider(
                                                            ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\get_llm_provider_logic.py", line 470, in get_llm_provider
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\get_llm_provider_logic.py", line 451, in get_llm_provider
    raise litellm.exceptions.BadRequestError(  # type: ignore
litellm.exceptions.BadRequestError: litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model={'model': 'groq/llama-3.1-8b-instant', 'max_tokens': 500, 'temperature': 0.7}
 Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers
2026-02-06 17:21:05 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x247804fbb50>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:22:32 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:22:32 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:22:33 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:22:33 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:22:38 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:22:38 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:22:38 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:22:38 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:22:38 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:22:38 - src.core.orchestrator - INFO - [orchestrator.py:150] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:22:38 - src.core.orchestrator - INFO - [orchestrator.py:151] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:22:38 - src.core.orchestrator - INFO - [orchestrator.py:154] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:22:38 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:22:38 - src.core.orchestrator - INFO - [orchestrator.py:118] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:22:38 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:22:39 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:22:39 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:22:40 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:22:40 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:22:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:22:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:22:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:22:43 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 17:22:43 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 17:22:43 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Create a compelling marketing copy that positions ...'
2026-02-06 17:22:44 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2588 characters in 1088.99ms
2026-02-06 17:22:44 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:22:44 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:22:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:22:45 - src.core.orchestrator - ERROR - [orchestrator.py:124] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5518, Requested 2604. Please try again in 21.22s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5518, Requested 2604. Please try again in 21.22s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 119, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5518, Requested 2604. Please try again in 21.22s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:23:24 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1df919447d0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:24:11 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1dff1131e90>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:30:38 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:30:38 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:30:39 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:30:39 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:30:43 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:30:43 - src.core.orchestrator - DEBUG - [orchestrator.py:26] - __init__() - Configured CrewAI native Groq support (key: gsk_xQGo4RRG6hE...)
2026-02-06 17:30:43 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:30:43 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:30:43 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:30:43 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:30:43 - src.core.orchestrator - INFO - [orchestrator.py:131] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:30:43 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:30:43 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:30:43 - src.core.orchestrator - INFO - [orchestrator.py:98] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:30:43 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:45 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 17:30:49 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 17:30:49 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 17:30:49 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write a marketing text for the campaign plan based...'
2026-02-06 17:30:50 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2477 characters in 1147.29ms
2026-02-06 17:30:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 17:30:50 - src.core.orchestrator - ERROR - [orchestrator.py:104] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5593, Requested 1665. Please try again in 12.58s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5593, Requested 1665. Please try again in 12.58s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 99, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5593, Requested 1665. Please try again in 12.58s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 17:31:26 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1d66a372850>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:32:13 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1d66e83b890>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:40:52 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:40:52 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:40:53 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:40:53 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:40:57 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:40:57 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:40:57 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:40:57 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:40:58 - crewai.utilities.llm_utils - ERROR - [llm_utils.py:32] - create_llm() - Error instantiating LLM from string: Google Gen AI native provider not available, to install: uv add "crewai[google-genai]"
2026-02-06 17:43:02 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:43:02 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:43:03 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:43:03 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:43:07 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:43:07 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:43:07 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:43:07 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:43:07 - crewai.utilities.llm_utils - ERROR - [llm_utils.py:32] - create_llm() - Error instantiating LLM from string: Google Gen AI native provider not available, to install: uv add "crewai[google-genai]"
2026-02-06 17:43:59 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:43:59 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:44:00 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:44:00 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:44:05 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:44:05 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:44:05 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:44:05 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:44:05 - crewai.utilities.llm_utils - ERROR - [llm_utils.py:32] - create_llm() - Error instantiating LLM from string: Google Gen AI native provider not available, to install: uv add "crewai[google-genai]"
2026-02-06 17:44:27 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:44:27 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:44:27 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:44:27 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:44:27 - crewai.utilities.llm_utils - ERROR - [llm_utils.py:32] - create_llm() - Error instantiating LLM from string: Google Gen AI native provider not available, to install: uv add "crewai[google-genai]"
2026-02-06 17:44:45 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:44:45 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:44:46 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:44:46 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:44:51 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:44:51 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:44:51 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:44:51 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:44:51 - crewai.utilities.llm_utils - ERROR - [llm_utils.py:32] - create_llm() - Error instantiating LLM from string: Google Gen AI native provider not available, to install: uv add "crewai[google-genai]"
2026-02-06 17:46:28 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:46:28 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:46:28 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:46:28 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:46:32 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:46:32 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:46:32 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:46:32 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:46:35 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:46:35 - src.core.orchestrator - INFO - [orchestrator.py:123] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:46:35 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:46:35 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:46:35 - src.core.orchestrator - INFO - [orchestrator.py:40] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:46:35 - src.core.orchestrator - INFO - [orchestrator.py:91] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:46:35 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:46:36 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 404 - models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-02-06 17:46:36 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:46:36 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 404 - models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-02-06 17:46:36 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:46:36 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 404 - models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-02-06 17:46:36 - src.core.orchestrator - ERROR - [orchestrator.py:97] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 92, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 331, in call
    return self._handle_completion(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1110, in _handle_completion
    raise e from e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1099, in _handle_completion
    response = self.client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 5041, in generate_content
    return self._generate_content(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 3843, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1331, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1167, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1144, in _request_once
    errors.APIError.raise_for_response(response)
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}
2026-02-06 17:47:20 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x27f6d64bd10>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:49:59 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:49:59 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:49:59 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:49:59 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:50:03 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:50:03 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:50:03 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:50:03 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:50:06 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:50:06 - src.core.orchestrator - INFO - [orchestrator.py:123] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:50:06 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:50:06 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:50:06 - src.core.orchestrator - INFO - [orchestrator.py:40] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:50:06 - src.core.orchestrator - INFO - [orchestrator.py:91] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:50:06 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:50:06 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 53.553708887s.
2026-02-06 17:50:06 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:50:06 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 53.392019616s.
2026-02-06 17:50:06 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:50:07 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 53.288304209s.
2026-02-06 17:50:07 - src.core.orchestrator - ERROR - [orchestrator.py:97] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 53.288304209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 92, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 331, in call
    return self._handle_completion(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1110, in _handle_completion
    raise e from e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1099, in _handle_completion
    response = self.client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 5041, in generate_content
    return self._generate_content(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 3843, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1331, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1167, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1144, in _request_once
    errors.APIError.raise_for_response(response)
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 53.288304209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}
2026-02-06 17:50:51 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x13efe20f290>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:52:23 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:52:23 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:52:24 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:52:24 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:52:29 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:52:29 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:52:29 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:52:29 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:52:32 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:52:32 - src.core.orchestrator - INFO - [orchestrator.py:123] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:52:32 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:52:32 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:52:32 - src.core.orchestrator - INFO - [orchestrator.py:40] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:52:32 - src.core.orchestrator - INFO - [orchestrator.py:91] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:52:32 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:52:33 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 27.322996537s.
2026-02-06 17:52:33 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:52:33 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 27.148396077s.
2026-02-06 17:52:33 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:52:33 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 27.037008117s.
2026-02-06 17:52:33 - src.core.orchestrator - ERROR - [orchestrator.py:97] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 27.037008117s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 92, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 331, in call
    return self._handle_completion(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1110, in _handle_completion
    raise e from e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1099, in _handle_completion
    response = self.client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 5041, in generate_content
    return self._generate_content(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 3843, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1331, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1167, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1144, in _request_once
    errors.APIError.raise_for_response(response)
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 27.037008117s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}
2026-02-06 17:53:15 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x226823635d0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 17:55:00 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:55:00 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 17:55:01 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 17:55:01 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 17:55:05 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 17:55:05 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 17:55:05 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 17:55:05 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 17:55:08 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 17:55:08 - src.core.orchestrator - INFO - [orchestrator.py:123] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 17:55:08 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 17:55:08 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 17:55:08 - src.core.orchestrator - INFO - [orchestrator.py:40] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 17:55:08 - src.core.orchestrator - INFO - [orchestrator.py:91] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 17:55:08 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:55:08 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 51.773357888s.
2026-02-06 17:55:08 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:55:08 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 51.684655281s.
2026-02-06 17:55:08 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 17:55:08 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 51.486092634s.
2026-02-06 17:55:08 - src.core.orchestrator - ERROR - [orchestrator.py:97] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 51.486092634s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 92, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 331, in call
    return self._handle_completion(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1110, in _handle_completion
    raise e from e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1099, in _handle_completion
    response = self.client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 5041, in generate_content
    return self._generate_content(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 3843, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1331, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1167, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1144, in _request_once
    errors.APIError.raise_for_response(response)
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 51.486092634s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}
2026-02-06 17:55:52 - crewai.telemetry.telemetry - ERROR - [telemetry.py:84] - export() - HTTPSConnectionPool(host='telemetry.crewai.com', port=4319): Max retries exceeded with url: /v1/traces (Caused by ConnectTimeoutError(<HTTPSConnection(host='telemetry.crewai.com', port=4319) at 0x1ae026ff5d0>, 'Connection to telemetry.crewai.com timed out. (connect timeout=30)'))
2026-02-06 20:06:33 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:06:33 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:06:33 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:06:33 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:06:38 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:06:38 - src.core.orchestrator - DEBUG - [orchestrator.py:25] - __init__() - Configured Gemini API (key: AIzaSyDvBYEXGT0...)
2026-02-06 20:06:38 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:06:38 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:06:42 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:06:42 - src.core.orchestrator - INFO - [orchestrator.py:123] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:06:42 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:06:42 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:06:42 - src.core.orchestrator - INFO - [orchestrator.py:40] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:06:42 - src.core.orchestrator - INFO - [orchestrator.py:91] - run_campaign() - Launching crew for campaign 'FitNow New Year Wellness Journey'...
2026-02-06 20:06:42 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 20:06:42 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 17.040270004s.
2026-02-06 20:06:42 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 20:06:43 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 16.834691001s.
2026-02-06 20:06:43 - root - INFO - [common.py:144] - safe_tool_conversion() - Gemini: Successfully validated tool 'brand_guideline_retriever'
2026-02-06 20:06:43 - root - ERROR - [completion.py:342] - call() - Google Gemini API error: 429 - You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 16.626950659s.
2026-02-06 20:06:43 - src.core.orchestrator - ERROR - [orchestrator.py:97] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 16.626950659s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 92, in run_campaign
    result = crew.kickoff()
             ^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 331, in call
    return self._handle_completion(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1110, in _handle_completion
    raise e from e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llms\providers\gemini\completion.py", line 1099, in _handle_completion
    response = self.client.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 5041, in generate_content
    return self._generate_content(
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\models.py", line 3843, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1331, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1167, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Python311\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\tenacity\__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\_api_client.py", line 1144, in _request_once
    errors.APIError.raise_for_response(response)
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\google\genai\errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\nPlease retry in 16.626950659s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}
2026-02-06 20:12:16 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:12:16 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:12:16 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:12:16 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:12:20 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:12:20 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_9vGWE83p06h...)
2026-02-06 20:12:20 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:12:20 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:12:21 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:12:21 - src.core.orchestrator - INFO - [orchestrator.py:164] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:12:21 - src.core.orchestrator - INFO - [orchestrator.py:165] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:12:21 - src.core.orchestrator - INFO - [orchestrator.py:168] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:12:21 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:12:21 - src.core.orchestrator - INFO - [orchestrator.py:54] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:12:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:12:21 - src.core.orchestrator - ERROR - [orchestrator.py:138] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"Invalid API Key","type":"invalid_request_error","code":"invalid_api_key"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Invalid API Key","type":"invalid_request_error","code":"invalid_api_key"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 67, in run_campaign
    plan_result = planning_crew.kickoff(inputs=inputs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"Invalid API Key","type":"invalid_request_error","code":"invalid_api_key"}}

2026-02-06 20:15:43 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:15:43 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:15:43 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:15:43 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:15:47 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:15:47 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:15:47 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:15:47 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:15:48 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:15:48 - src.core.orchestrator - INFO - [orchestrator.py:164] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:15:48 - src.core.orchestrator - INFO - [orchestrator.py:165] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:15:48 - src.core.orchestrator - INFO - [orchestrator.py:168] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:15:48 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:15:48 - src.core.orchestrator - INFO - [orchestrator.py:54] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:15:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:15:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:15:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:15:49 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:15:49 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:15:49 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:15:49 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:15:49 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:15:49 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:15:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:15:51 - src.core.orchestrator - INFO - [orchestrator.py:68] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:16:06 - src.core.orchestrator - INFO - [orchestrator.py:72] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:16:06 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:16:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:16:08 - src.core.orchestrator - INFO - [orchestrator.py:88] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:16:23 - src.core.orchestrator - INFO - [orchestrator.py:106] - run_campaign() -  STAGE 3: Generating Content...
2026-02-06 20:16:23 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:16:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:16:25 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:16:25 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:16:25 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write marketing text for FitNow's New Year Wellnes...'
2026-02-06 20:16:26 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2150 characters in 1337.30ms
2026-02-06 20:16:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:16:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:16:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:16:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:16:27 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 20:16:29 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: ReplicateError Details:
title: Unauthenticated
status: 401
detail: You did not pass a valid authentication token
2026-02-06 20:16:29 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:16:29 - src.core.orchestrator - ERROR - [orchestrator.py:138] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5532, Requested 2662. Please try again in 21.939999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5532, Requested 2662. Please try again in 21.939999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 128, in run_campaign
    final_result = content_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 5532, Requested 2662. Please try again in 21.939999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 20:18:36 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:18:36 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:18:36 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:18:37 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:18:40 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:18:40 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:18:40 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:18:40 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:18:41 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:18:41 - src.core.orchestrator - INFO - [orchestrator.py:165] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:18:41 - src.core.orchestrator - INFO - [orchestrator.py:166] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:18:41 - src.core.orchestrator - INFO - [orchestrator.py:169] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:18:41 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:18:41 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:18:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:18:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:18:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:18:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:18:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:18:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:18:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:18:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:18:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:18:44 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:18:44 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:19:14 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:19:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:19:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:19:15 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:19:45 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3: Generating Content...
2026-02-06 20:19:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:19:45 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:19:46 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:19:46 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:19:46 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write marketing text for the FitNow New Year Welln...'
2026-02-06 20:19:47 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1960 characters in 1159.18ms
2026-02-06 20:19:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:19:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:19:47 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Based on the provided marketing text, refine the t...'
2026-02-06 20:19:47 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 527 characters in 312.38ms
2026-02-06 20:19:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:19:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:19:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:19:48 - src.core.orchestrator - ERROR - [orchestrator.py:139] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4340, Requested 2321. Please try again in 6.609999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4340, Requested 2321. Please try again in 6.609999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 129, in run_campaign
    final_result = content_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4340, Requested 2321. Please try again in 6.609999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 20:23:04 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:23:04 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:23:04 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:23:04 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:23:08 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:23:08 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:23:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:23:08 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:23:08 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:23:08 - src.core.orchestrator - INFO - [orchestrator.py:180] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:23:08 - src.core.orchestrator - INFO - [orchestrator.py:181] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:23:08 - src.core.orchestrator - INFO - [orchestrator.py:184] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:23:08 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:23:08 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:23:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:23:09 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:23:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:23:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:23:11 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:23:41 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:23:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:23:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:23:42 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:24:12 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 20:24:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:24:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:24:13 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:24:13 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:24:13 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Create a comprehensive marketing text for the FitN...'
2026-02-06 20:24:14 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 2583 characters in 1258.02ms
2026-02-06 20:24:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:24:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:24:15 - src.core.orchestrator - INFO - [orchestrator.py:122] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 20:24:45 - src.core.orchestrator - INFO - [orchestrator.py:126] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 20:24:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:24:45 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:24:45 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 20:24:46 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: ReplicateError Details:
title: Unauthenticated
status: 401
detail: You did not pass a valid authentication token
2026-02-06 20:24:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:24:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:24:47 - src.core.orchestrator - INFO - [orchestrator.py:142] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 20:24:47 - src.core.orchestrator - INFO - [orchestrator.py:192] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 20:24:47 - src.core.orchestrator - INFO - [orchestrator.py:195] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 20:30:06 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:30:06 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:30:06 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:30:06 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:30:11 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:30:11 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:30:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:30:11 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:30:11 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:30:11 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:30:11 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:30:11 - src.core.orchestrator - INFO - [orchestrator.py:205] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:30:11 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:30:11 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:30:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:14 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:30:44 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:30:44 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:30:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:30:46 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:31:16 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 20:31:16 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:31:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:31:17 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:31:17 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:31:17 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 20:31:21 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1825 characters in 4079.58ms
2026-02-06 20:31:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:31:21 - src.core.orchestrator - ERROR - [orchestrator.py:175] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'bravery_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=bravery_search\u003e{\"q\":\"FitNow New Year Wellness Journey target audience\", \"num_topics\": \"3\"}}\u003c/function\u003e\n\n"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'bravery_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=bravery_search\u003e{\"q\":\"FitNow New Year Wellness Journey target audience\", \"num_topics\": \"3\"}}\u003c/function\u003e\n\n"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 132, in run_campaign
    text_result = text_crew.kickoff()
                  ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'bravery_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=bravery_search\u003e{\"q\":\"FitNow New Year Wellness Journey target audience\", \"num_topics\": \"3\"}}\u003c/function\u003e\n\n"}}

2026-02-06 20:33:10 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:33:10 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:33:10 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:33:10 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:33:15 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:33:15 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:33:15 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:33:15 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:33:15 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:33:15 - src.core.orchestrator - INFO - [orchestrator.py:191] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:33:15 - src.core.orchestrator - INFO - [orchestrator.py:192] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:33:15 - src.core.orchestrator - INFO - [orchestrator.py:195] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:33:15 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:33:15 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:33:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:33:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:33:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:33:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:33:16 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:33:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:33:16 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:33:18 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:33:18 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:33:48 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:33:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:33:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:33:48 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:34:18 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 20:34:18 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:34:19 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:34:19 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:34:19 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:34:19 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 20:34:20 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1683 characters in 1065.46ms
2026-02-06 20:34:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:34:21 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:34:21 - src.core.orchestrator - INFO - [orchestrator.py:128] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 20:34:51 - src.core.orchestrator - INFO - [orchestrator.py:132] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 20:34:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:34:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:34:51 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 20:34:52 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: ReplicateError Details:
title: Unauthenticated
status: 401
detail: You did not pass a valid authentication token
2026-02-06 20:34:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:34:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:34:52 - src.core.orchestrator - INFO - [orchestrator.py:153] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 20:34:52 - src.core.orchestrator - INFO - [orchestrator.py:203] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 20:34:52 - src.core.orchestrator - INFO - [orchestrator.py:206] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 20:40:20 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:40:20 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:40:20 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:40:20 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:40:26 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:40:26 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:40:26 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:40:26 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:40:26 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:40:26 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:40:26 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:40:26 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:40:26 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:40:26 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:40:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:40:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:40:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:40:27 - src.core.orchestrator - ERROR - [orchestrator.py:170] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_guideline_retriever\":{\"query\": \"FitNow New Year Wellness Journey brand guidelines for voice, tone, target audience, visual identity, and messaging framework\"}\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_guideline_retriever\":{\"query\": \"FitNow New Year Wellness Journey brand guidelines for voice, tone, target audience, visual identity, and messaging framework\"}\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 68, in run_campaign
    plan_result = planning_crew.kickoff(inputs=inputs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brand_guideline_retriever\":{\"query\": \"FitNow New Year Wellness Journey brand guidelines for voice, tone, target audience, visual identity, and messaging framework\"}\u003c/function\u003e"}}

2026-02-06 20:40:48 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:40:48 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:40:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:40:48 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:40:48 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:40:48 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:40:48 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:40:48 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:40:48 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:40:48 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:40:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:40:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:40:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:40:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:40:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:40:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:40:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:40:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:40:52 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:41:22 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:41:22 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:41:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:41:23 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:41:53 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 20:41:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:41:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:41:54 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:41:54 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:41:54 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 20:41:55 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1515 characters in 994.77ms
2026-02-06 20:41:55 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:41:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:41:56 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 20:42:26 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 20:42:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:42:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:42:26 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 20:42:28 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: ReplicateError Details:
title: Unauthenticated
status: 401
detail: You did not pass a valid authentication token
2026-02-06 20:42:28 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:42:28 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:42:28 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:42:28 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:42:28 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:42:28 - src.core.orchestrator - ERROR - [orchestrator.py:170] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4537, Requested 1790. Please try again in 3.27s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4537, Requested 1790. Please try again in 3.27s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 156, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4537, Requested 1790. Please try again in 3.27s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 20:46:40 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:46:40 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:46:41 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:46:41 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:46:45 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:46:45 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:46:45 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:46:45 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:46:45 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:46:45 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:46:45 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:46:45 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:46:45 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:46:45 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:46:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:45 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:46:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:46:48 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:47:18 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:47:18 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:47:19 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:47:19 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:47:49 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 20:47:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:47:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:47:50 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:47:50 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:47:50 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 20:47:51 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1443 characters in 962.68ms
2026-02-06 20:47:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:47:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:47:52 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 20:48:22 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 20:48:22 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:48:22 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:48:22 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 20:48:23 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: ReplicateError Details:
title: Unauthenticated
status: 401
detail: You did not pass a valid authentication token
2026-02-06 20:48:23 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:48:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:48:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:48:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:48:24 - src.core.orchestrator - INFO - [orchestrator.py:158] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 20:48:24 - src.core.orchestrator - INFO - [orchestrator.py:208] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 20:48:24 - src.core.orchestrator - INFO - [orchestrator.py:211] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 20:52:19 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:52:19 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 20:52:19 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 20:52:19 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 20:52:23 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 20:52:23 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 20:52:23 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cpu
2026-02-06 20:52:23 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 20:52:24 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 20:52:24 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 20:52:24 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 20:52:24 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 20:52:24 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 20:52:24 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 20:52:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:52:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:52:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:52:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:52:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:52:25 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:52:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:52:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:52:26 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:52:56 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 20:52:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 20:52:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:52:57 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 20:53:27 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 20:53:27 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:53:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:53:28 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 20:53:28 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 20:53:28 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 20:53:29 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1258 characters in 955.60ms
2026-02-06 20:53:29 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:53:29 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:53:29 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 20:53:59 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 20:53:59 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:54:00 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:54:00 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-06 20:54:00 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: ReplicateError Details:
title: Unauthenticated
status: 401
detail: You did not pass a valid authentication token
2026-02-06 20:54:00 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:54:01 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 20:54:01 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 20:54:01 - src.core.orchestrator - ERROR - [orchestrator.py:170] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"prompt\":\"image generation tool without authentication token, replicate delivery error, unauthenticated status 401, replicate error unauthenticated detail you did not pass a valid authentication token, replicate delivery tool failure unauthenticated, replicate delivery api key missing, replicate delivery authentication failed, replicate error unauthenticated, replicate delivery error message you did not pass a valid authentication token\"}\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"prompt\":\"image generation tool without authentication token, replicate delivery error, unauthenticated status 401, replicate error unauthenticated detail you did not pass a valid authentication token, replicate delivery tool failure unauthenticated, replicate delivery api key missing, replicate delivery authentication failed, replicate error unauthenticated, replicate delivery error message you did not pass a valid authentication token\"}\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 156, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"prompt\":\"image generation tool without authentication token, replicate delivery error, unauthenticated status 401, replicate error unauthenticated detail you did not pass a valid authentication token, replicate delivery tool failure unauthenticated, replicate delivery api key missing, replicate delivery authentication failed, replicate error unauthenticated, replicate delivery error message you did not pass a valid authentication token\"}\u003c/function\u003e"}}

2026-02-06 21:44:43 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 21:44:43 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 21:44:43 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 21:44:43 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 21:44:52 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 21:44:52 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 21:44:52 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:219] - __init__() - Use pytorch device_name: cuda:0
2026-02-06 21:44:52 - sentence_transformers.SentenceTransformer - INFO - [SentenceTransformer.py:227] - __init__() - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2026-02-06 21:44:53 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 21:44:53 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 21:44:53 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 21:44:53 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 21:44:53 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 21:44:53 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 21:44:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:44:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:44:54 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:44:54 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:44:54 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:44:55 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:44:55 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 21:45:25 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 21:45:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:45:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:45:27 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 21:45:57 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 21:45:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:45:58 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:45:58 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 21:45:58 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 21:45:58 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 21:45:59 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1372 characters in 786.72ms
2026-02-06 21:45:59 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:46:00 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:46:00 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 21:46:30 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 21:46:30 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:46:30 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:46:30 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 21:46:30 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 21:46:41 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770394601.png in 10.74s
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:46:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:46:42 - src.core.orchestrator - ERROR - [orchestrator.py:170] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"kwargs\": {\"query\": \"image generation tool replicate delivery url example\"}}\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"kwargs\": {\"query\": \"image generation tool replicate delivery url example\"}}\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 156, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"kwargs\": {\"query\": \"image generation tool replicate delivery url example\"}}\u003c/function\u003e"}}

2026-02-06 21:49:05 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 21:49:05 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 21:49:06 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 21:49:06 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 21:49:12 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 21:49:12 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 21:49:12 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 21:49:12 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 21:49:12 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 21:49:12 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 21:49:12 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 21:49:12 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 21:49:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:49:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:49:14 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 21:49:44 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 21:49:44 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:49:45 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:49:45 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 21:50:15 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 21:50:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:50:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:50:16 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 21:50:16 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 21:50:16 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 21:50:17 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1302 characters in 723.78ms
2026-02-06 21:50:17 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:50:17 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:50:17 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 21:50:47 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 21:50:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:50:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:50:48 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 21:50:48 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 21:50:59 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770394859.png in 11.25s
2026-02-06 21:50:59 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:50:59 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:50:59 - src.core.orchestrator - INFO - [orchestrator.py:158] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 21:50:59 - src.core.orchestrator - INFO - [orchestrator.py:208] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 21:50:59 - src.core.orchestrator - INFO - [orchestrator.py:211] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 21:55:41 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 21:55:41 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 21:55:42 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 21:55:42 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 21:55:48 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 21:55:48 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 21:55:48 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 21:55:48 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 21:55:48 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 21:55:48 - src.core.orchestrator - INFO - [orchestrator.py:200] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 21:55:48 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 21:55:48 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 21:55:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:55:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:55:50 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 21:56:20 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 21:56:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 21:56:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:56:23 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 21:56:53 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 21:56:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:56:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 21:56:53 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 21:56:53 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 21:56:53 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 21:56:54 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1336 characters in 753.51ms
2026-02-06 21:56:54 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 21:56:55 - src.core.orchestrator - ERROR - [orchestrator.py:170] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"The requirements were partially met.\n\n\u003cfunction=image_generation_tool\u003e{\"prompt\":\"A diverse group of people from different age groups and ethnicities exercising together in a park on a sunny day. They are smiling and supporting each other in the pursuit of a healthy lifestyle.\"\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"The requirements were partially met.\n\n\u003cfunction=image_generation_tool\u003e{\"prompt\":\"A diverse group of people from different age groups and ethnicities exercising together in a park on a sunny day. They are smiling and supporting each other in the pursuit of a healthy lifestyle.\"\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 129, in run_campaign
    text_result = text_crew.kickoff()
                  ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"The requirements were partially met.\n\n\u003cfunction=image_generation_tool\u003e{\"prompt\":\"A diverse group of people from different age groups and ethnicities exercising together in a park on a sunny day. They are smiling and supporting each other in the pursuit of a healthy lifestyle.\"\u003c/function\u003e"}}

2026-02-06 22:00:41 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:00:41 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:00:41 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 22:00:41 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 22:00:47 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 22:00:47 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 22:00:47 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 22:00:47 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 22:00:47 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 22:00:47 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 22:00:47 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 22:00:47 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 22:00:47 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:00:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:00:50 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:01:20 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 22:01:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:01:22 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:01:22 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:01:52 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 22:01:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:01:52 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:01:53 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 22:01:53 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 22:01:53 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 22:01:53 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1292 characters in 770.05ms
2026-02-06 22:01:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:01:54 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:01:54 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 22:02:24 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 22:02:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:02:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:02:24 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:02:24 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 22:02:34 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770395554.png in 9.98s
2026-02-06 22:02:34 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:02:34 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:02:34 - src.core.orchestrator - INFO - [orchestrator.py:160] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 22:02:34 - src.core.orchestrator - INFO - [orchestrator.py:210] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 22:02:34 - src.core.orchestrator - INFO - [orchestrator.py:213] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 22:07:02 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:07:02 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:07:02 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 22:07:02 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 22:07:08 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 22:07:08 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 22:07:08 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 22:07:08 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 22:07:08 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 22:07:08 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 22:07:08 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 22:07:08 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 22:07:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:07:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:07:11 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:07:41 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 22:07:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:07:44 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:07:44 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:08:14 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 22:08:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:15 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 22:08:15 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 22:08:15 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 22:08:16 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1259 characters in 820.37ms
2026-02-06 22:08:16 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:16 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 22:08:46 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 22:08:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:47 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:08:47 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 22:08:57 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770395937.png in 10.41s
2026-02-06 22:08:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:58 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:58 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:08:58 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:08:58 - src.core.orchestrator - INFO - [orchestrator.py:160] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 22:08:58 - src.core.orchestrator - INFO - [orchestrator.py:210] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 22:08:58 - src.core.orchestrator - INFO - [orchestrator.py:213] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 22:12:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:12:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:12:03 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 22:12:03 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 22:12:09 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 22:12:09 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 22:12:09 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 22:12:09 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 22:12:09 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 22:12:09 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 22:12:09 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 22:12:09 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 22:12:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:12:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:12:12 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:12:42 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 22:12:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:12:43 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:12:43 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:13:13 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 22:13:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:13:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:13:14 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 22:13:14 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 22:13:14 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 22:13:15 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1398 characters in 794.42ms
2026-02-06 22:13:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:13:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:13:15 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 22:13:45 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 22:13:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:13:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:13:46 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:13:46 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 22:13:56 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770396235.png in 9.79s
2026-02-06 22:13:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:13:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:13:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:13:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:13:56 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:13:56 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic. Generated via Hugging Face Inference API'...
2026-02-06 22:14:06 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770396246.png in 9.57s
2026-02-06 22:14:06 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:14:06 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:14:06 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:14:06 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic. Generated via Hugging Face Inference API. Image must be publicly accessible on replicate.delivery'...
2026-02-06 22:14:16 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770396255.png in 9.54s
2026-02-06 22:14:16 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:14:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:14:16 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:14:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:14:16 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:14:16 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic. Generated via Hugging Face Inference API. Image must be publicly accessible on replicate.delivery. URL should be in format of https://replicate.delivery/...'...
2026-02-06 22:14:25 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770396265.png in 9.08s
2026-02-06 22:14:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:14:25 - src.core.orchestrator - ERROR - [orchestrator.py:172] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4664, Requested 1834. Please try again in 4.98s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4664, Requested 1834. Please try again in 4.98s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 158, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 382, in exception_type
    raise RateLimitError(
litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: GroqException - {"error":{"message":"Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01kbexkrg6f1p845n42wgnpyn0` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 4664, Requested 1834. Please try again in 4.98s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing","type":"tokens","code":"rate_limit_exceeded"}}

2026-02-06 22:16:30 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:16:30 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:16:31 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 22:16:31 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 22:16:37 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 22:16:37 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 22:16:37 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 22:16:37 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 22:16:37 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 22:16:37 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 22:16:37 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 22:16:37 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 22:16:37 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:16:40 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:16:40 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:17:10 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 22:17:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:17:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:17:12 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:17:42 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 22:17:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:17:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:17:42 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 22:17:42 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 22:17:42 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 22:17:43 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1367 characters in 855.97ms
2026-02-06 22:17:43 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:17:44 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:17:44 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 22:18:14 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 22:18:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:18:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:18:14 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:18:14 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 22:18:24 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770396504.png in 9.85s
2026-02-06 22:18:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:18:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:18:24 - src.core.orchestrator - INFO - [orchestrator.py:160] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 22:18:24 - src.core.orchestrator - INFO - [orchestrator.py:210] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 22:18:24 - src.core.orchestrator - INFO - [orchestrator.py:213] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 22:31:25 - watchfiles.main - INFO - [main.py:308] - _log_changes() - 1 change detected
2026-02-06 22:32:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:32:03 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 22:32:04 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 22:32:04 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 22:32:17 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 22:32:17 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 22:32:17 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 22:32:17 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 22:32:17 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 22:32:17 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 22:32:17 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 22:32:17 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 22:32:17 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:32:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:32:20 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:32:50 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 22:32:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:32:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:32:51 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:33:21 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 22:33:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:33:21 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:33:22 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 22:33:22 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 22:33:22 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 22:33:23 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1341 characters in 851.50ms
2026-02-06 22:33:23 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:33:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:33:23 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 22:33:53 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 22:33:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:33:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:33:53 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:33:53 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 22:34:03 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770397443.png in 9.84s
2026-02-06 22:34:03 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:34:04 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:34:04 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:34:04 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:34:04 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:34:04 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic. This is the second attempt so the generated image should be exactly as requested.'...
2026-02-06 22:34:13 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770397453.png in 9.16s
2026-02-06 22:34:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:34:13 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:34:13 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:34:13 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. The person is female with short brown hair and wearing a fitness top and leggings. Calming light blue and creamy tones with a sense of depth using subtle focus blur. The image should be a photo-realistic 1200x800 high quality image. The generated image should be exactly as requested.'...
2026-02-06 22:34:22 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770397462.png in 8.85s
2026-02-06 22:34:22 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:34:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:34:23 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:34:23 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. The person is female with short brown hair and wearing a fitness top and leggings. Calming light blue and creamy tones with a sense of depth using subtle focus blur. The image should be a photo-realistic 1200x800 high quality image. To make the image look even better, make sure the generated image has the correct colors of the sky, that is: blue on the top (near the horizon) gradually turns into a light pink and then a warm orange and finally yellow towards the sun. The generated image should be exactly as requested.'...
2026-02-06 22:34:32 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770397472.png in 9.38s
2026-02-06 22:34:32 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:34:32 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:34:32 - src.core.orchestrator - INFO - [orchestrator.py:160] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 22:34:32 - src.core.orchestrator - INFO - [orchestrator.py:210] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 22:34:32 - src.core.orchestrator - INFO - [orchestrator.py:213] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 22:36:51 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 22:36:51 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 22:36:51 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 22:36:51 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 22:36:51 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 22:36:51 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 22:36:51 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 22:36:51 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 22:36:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:36:54 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:36:54 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:37:24 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 22:37:24 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 22:37:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:37:26 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 22:37:56 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 22:37:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:37:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:37:56 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 22:37:57 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1349 characters in 605.27ms
2026-02-06 22:37:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:37:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:37:57 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 22:38:27 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 22:38:27 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:38:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:38:27 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 22:38:27 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 22:38:37 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770397717.png in 9.64s
2026-02-06 22:38:37 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:38:37 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:38:37 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 22:38:37 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 22:38:37 - src.core.orchestrator - INFO - [orchestrator.py:160] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 22:38:37 - src.core.orchestrator - INFO - [orchestrator.py:210] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 22:38:37 - src.core.orchestrator - INFO - [orchestrator.py:213] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 23:30:32 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:30:32 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:30:34 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 23:30:34 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 23:31:03 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 23:31:03 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 23:31:03 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 23:31:03 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 23:31:03 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 23:31:03 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 23:31:03 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 23:31:03 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 23:31:03 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:31:05 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:31:05 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:31:35 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 23:31:35 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:31:37 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:31:37 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:32:07 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 23:32:07 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:32:07 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:32:08 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 23:32:08 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 23:32:08 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 23:32:09 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1455 characters in 965.69ms
2026-02-06 23:32:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:32:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:32:10 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 23:32:10 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A group of diverse people from all ages and fitness levels participating in various wellness activities, such as yoga, jogging, and weightlifting, with a bright and vibrant background that conveys energy, motivation, and community.'...
2026-02-06 23:32:20 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770400940.png in 10.02s
2026-02-06 23:32:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:32:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:32:20 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 23:32:50 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 23:32:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:32:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:32:51 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 23:32:51 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 23:33:00 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770400979.png in 8.81s
2026-02-06 23:33:00 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:33:00 - src.core.orchestrator - ERROR - [orchestrator.py:172] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"query\":\"https://replicate.delivery/\"}\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"query\":\"https://replicate.delivery/\"}\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 158, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"query\":\"https://replicate.delivery/\"}\u003c/function\u003e"}}

2026-02-06 23:36:55 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:36:55 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:36:56 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 23:36:56 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 23:37:09 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 23:37:09 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 23:37:09 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 23:37:09 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 23:37:09 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 23:37:09 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 23:37:09 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 23:37:09 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 23:37:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:37:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:37:12 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:37:42 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 23:37:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:37:43 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:37:43 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:38:13 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 23:38:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:38:13 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:38:14 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 23:38:14 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 23:38:14 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 23:38:15 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1271 characters in 831.78ms
2026-02-06 23:38:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:38:16 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:38:16 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 23:38:46 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 23:38:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:38:46 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:38:46 - src.core.orchestrator - INFO - [orchestrator.py:159] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 23:38:46 - src.core.orchestrator - INFO - [orchestrator.py:209] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 23:38:46 - src.core.orchestrator - INFO - [orchestrator.py:212] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 23:42:59 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:42:59 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:42:59 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 23:42:59 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 23:43:04 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 23:43:04 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 23:43:04 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 23:43:04 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 23:43:04 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 23:43:04 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 23:43:04 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 23:43:04 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 23:43:05 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:43:07 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:43:07 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:43:37 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 23:43:37 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:43:38 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:43:38 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:44:08 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 23:44:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:44:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:44:09 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 23:44:09 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 23:44:09 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 23:44:10 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1412 characters in 871.83ms
2026-02-06 23:44:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:44:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:44:10 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 23:44:40 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 23:44:40 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:44:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:44:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:44:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:44:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:44:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:44:41 - src.core.orchestrator - ERROR - [orchestrator.py:171] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: Invalid response from LLM call - None or empty.
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 480, in _invoke_loop_native_tools
    formatted_answer = handle_max_iterations_exceeded(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 257, in handle_max_iterations_exceeded
    raise ValueError("Invalid response from LLM call - None or empty.")
ValueError: Invalid response from LLM call - None or empty.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 480, in _invoke_loop_native_tools
    formatted_answer = handle_max_iterations_exceeded(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 257, in handle_max_iterations_exceeded
    raise ValueError("Invalid response from LLM call - None or empty.")
ValueError: Invalid response from LLM call - None or empty.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 157, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 480, in _invoke_loop_native_tools
    formatted_answer = handle_max_iterations_exceeded(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 257, in handle_max_iterations_exceeded
    raise ValueError("Invalid response from LLM call - None or empty.")
ValueError: Invalid response from LLM call - None or empty.
2026-02-06 23:46:56 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:46:56 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-06 23:46:57 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-06 23:46:57 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-06 23:47:02 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 23:47:02 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 23:47:02 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 23:47:02 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 23:47:02 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 23:47:02 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 23:47:02 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 23:47:02 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 23:47:02 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:47:05 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:47:05 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:47:35 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 23:47:35 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:47:37 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:47:37 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:48:07 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 23:48:07 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:48:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:48:09 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-06 23:48:09 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-06 23:48:09 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 23:48:10 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1660 characters in 841.68ms
2026-02-06 23:48:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:48:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:48:10 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 23:48:40 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 23:48:40 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:48:40 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:48:40 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 23:48:40 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 23:48:51 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770401931.png in 10.78s
2026-02-06 23:48:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:48:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:48:51 - src.core.orchestrator - INFO - [orchestrator.py:159] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 23:48:51 - src.core.orchestrator - INFO - [orchestrator.py:209] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-06 23:48:51 - src.core.orchestrator - INFO - [orchestrator.py:212] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-06 23:52:37 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-06 23:52:37 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-06 23:52:37 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-06 23:52:37 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-06 23:52:37 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-06 23:52:37 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 23:52:37 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 23:52:37 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 23:52:37 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:52:39 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:52:39 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:53:09 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 23:53:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:53:11 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:53:11 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:53:41 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 23:53:41 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:53:41 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:53:41 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-06 23:53:42 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1601 characters in 688.06ms
2026-02-06 23:53:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:53:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:53:42 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 23:54:12 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 23:54:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:54:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:54:12 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-06 23:54:12 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-06 23:54:22 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770402262.png in 9.87s
2026-02-06 23:54:22 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:54:22 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:54:22 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:54:22 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:54:22 - src.core.orchestrator - INFO - [orchestrator.py:159] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-06 23:54:22 - src.core.orchestrator - INFO - [orchestrator.py:209] - run_with_auto_regeneration() - Plan Validation Status: rejected
2026-02-06 23:54:22 - src.core.orchestrator - WARNING - [orchestrator.py:222] - run_with_auto_regeneration() -  Plan validation failed on attempt 1. Regenerating plan with feedback...
2026-02-06 23:54:22 - src.core.orchestrator - DEBUG - [orchestrator.py:329] - _enhance_objective_for_plan_retry() - Enhanced objective for plan retry attempt 2: ["Address validator feedback: Validator feedback: \\n\\n'''**campaign plan: fitnow new year wellness journey**\\n\\n**campaign objective:**\\nencourage participants to embark on a holistic wellness journey, leveraging fitnow's expertise and resources to a"]
2026-02-06 23:54:22 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 2/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-06 23:54:22 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-06 23:54:22 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-06 23:54:23 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:54:24 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:54:24 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:54:54 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-06 23:54:54 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-06 23:54:56 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:54:56 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-06 23:55:26 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-06 23:55:26 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:55:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:55:26 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-06 23:55:56 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-06 23:55:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:55:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:55:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:55:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:55:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-06 23:55:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-06 23:55:57 - src.core.orchestrator - ERROR - [orchestrator.py:171] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: Invalid response from LLM call - None or empty.
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 480, in _invoke_loop_native_tools
    formatted_answer = handle_max_iterations_exceeded(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 257, in handle_max_iterations_exceeded
    raise ValueError("Invalid response from LLM call - None or empty.")
ValueError: Invalid response from LLM call - None or empty.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 480, in _invoke_loop_native_tools
    formatted_answer = handle_max_iterations_exceeded(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 257, in handle_max_iterations_exceeded
    raise ValueError("Invalid response from LLM call - None or empty.")
ValueError: Invalid response from LLM call - None or empty.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 157, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 493, in execute_task
    result = self.execute_task(task, context, tools)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 492, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 579, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 480, in _invoke_loop_native_tools
    formatted_answer = handle_max_iterations_exceeded(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 257, in handle_max_iterations_exceeded
    raise ValueError("Invalid response from LLM call - None or empty.")
ValueError: Invalid response from LLM call - None or empty.
2026-02-07 00:02:00 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:02:00 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:02:00 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 00:02:00 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 00:02:06 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 00:02:06 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 00:02:06 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 00:02:06 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 00:02:06 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 00:02:06 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 00:02:06 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 00:02:06 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 00:02:06 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:02:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:02:08 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:02:38 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 00:02:38 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:02:40 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:02:40 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:03:10 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 00:03:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:03:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:03:11 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 00:03:11 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 00:03:11 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 00:03:11 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1076 characters in 711.51ms
2026-02-07 00:03:11 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:03:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:03:12 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-07 00:03:42 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 00:03:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:03:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:03:42 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 00:03:42 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 00:03:52 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770402832.png in 10.40s
2026-02-07 00:03:52 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:03:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:03:53 - src.core.orchestrator - INFO - [orchestrator.py:159] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 00:03:53 - src.core.orchestrator - INFO - [orchestrator.py:209] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 00:03:53 - src.core.orchestrator - INFO - [orchestrator.py:212] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 00:13:37 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:13:37 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:13:37 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 00:13:37 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 00:13:45 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 00:13:45 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 00:13:45 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 00:13:45 - src.core.orchestrator - INFO - [orchestrator.py:197] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 00:13:45 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 00:13:45 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 00:13:45 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 00:13:45 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 00:13:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:13:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:13:47 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:14:17 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 00:14:17 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:14:18 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:14:18 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:14:48 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 00:14:49 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:14:49 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:14:50 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 00:14:50 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 00:14:50 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 00:14:50 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1389 characters in 808.05ms
2026-02-07 00:14:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:14:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:14:51 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-07 00:15:21 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 00:15:21 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:15:21 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:15:21 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 00:15:21 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 00:15:31 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770403531.png in 9.56s
2026-02-07 00:15:31 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:15:31 - src.core.orchestrator - ERROR - [orchestrator.py:171] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration failed: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"search_terms\":\"https //brilliant.org/static/generated/img_hf_1770403531.png\"}\u003c/function\u003e"}}
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 221, in _make_common_sync_call
    response = sync_httpx_client.post(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1028, in post
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\http_handler.py", line 1010, in post
    response.raise_for_status()
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.groq.com/openai/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 2191, in completion
    response = base_llm_http_handler.completion(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 524, in completion
    response = self._make_common_sync_call(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 246, in _make_common_sync_call
    raise self._handle_error(e=e, provider_config=provider_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\llms\custom_httpx\llm_http_handler.py", line 4505, in _handle_error
    raise provider_config.get_error_class(
litellm.llms.openai.common_utils.OpenAIError: {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"search_terms\":\"https //brilliant.org/static/generated/img_hf_1770403531.png\"}\u003c/function\u003e"}}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\src\core\orchestrator.py", line 157, in run_campaign
    image_result = image_crew.kickoff()
                   ^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 743, in kickoff
    result = self._run_sequential_process()
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1150, in _run_sequential_process
    return self._execute_tasks(self.tasks)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\crew.py", line 1236, in _execute_tasks
    task_output = task.execute_sync(
                  ^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 499, in execute_sync
    return self._execute_core(agent, context, tools)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 740, in _execute_core
    raise e  # Re-raise the exception after emitting the event
    ^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\task.py", line 671, in _execute_core
    result = agent.execute_task(
             ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 481, in execute_task
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 459, in execute_task
    result = self._execute_without_timeout(task_prompt, task)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agent\core.py", line 568, in _execute_without_timeout
    return self.agent_executor.invoke(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 207, in invoke
    formatted_answer = self._invoke_loop()
                       ^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 305, in _invoke_loop
    return self._invoke_loop_native_tools()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 566, in _invoke_loop_native_tools
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\agents\crew_agent_executor.py", line 498, in _invoke_loop_native_tools
    answer = get_llm_response(
             ^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 372, in get_llm_response
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\utilities\agent_utils.py", line 362, in get_llm_response
    answer = llm.call(
             ^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1719, in call
    result = self._handle_non_streaming_response(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\llm.py", line 1169, in _handle_non_streaming_response
    response = litellm.completion(**params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1748, in wrapper
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\utils.py", line 1569, in wrapper
    result = original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\main.py", line 4305, in completion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2378, in exception_type
    raise e
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 444, in exception_type
    raise BadRequestError(
litellm.exceptions.BadRequestError: litellm.BadRequestError: GroqException - {"error":{"message":"tool call validation failed: attempted to call tool 'brave_search' which was not in request.tools","type":"invalid_request_error","code":"tool_use_failed","failed_generation":"\u003cfunction=brave_search\u003e{\"search_terms\":\"https //brilliant.org/static/generated/img_hf_1770403531.png\"}\u003c/function\u003e"}}

2026-02-07 00:17:21 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:17:21 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:17:21 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 00:17:21 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 00:17:28 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 00:17:28 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 00:17:28 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 00:17:28 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 00:17:28 - src.core.orchestrator - INFO - [orchestrator.py:203] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 00:17:28 - src.core.orchestrator - INFO - [orchestrator.py:206] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 00:17:28 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 00:17:28 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 00:17:28 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:17:31 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:17:31 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:18:01 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 00:18:01 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:18:02 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:18:02 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:18:32 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 00:18:32 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:18:32 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:18:33 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 00:18:33 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 00:18:33 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 00:18:34 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1413 characters in 848.77ms
2026-02-07 00:18:34 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:18:34 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:18:34 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-07 00:19:04 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 00:19:04 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:19:05 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:19:05 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 00:19:05 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 00:19:15 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770403755.png in 10.39s
2026-02-07 00:19:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:19:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:19:15 - src.core.orchestrator - INFO - [orchestrator.py:164] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 00:19:15 - src.core.orchestrator - INFO - [orchestrator.py:214] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 00:19:15 - src.core.orchestrator - INFO - [orchestrator.py:217] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 00:19:15 - src.routes.api_routes - ERROR - [api_routes.py:347] - _save_orchestration_results() - Failed to save results: (psycopg2.errors.CheckViolation) new row for relation "image_contents" violates check constraint "chk_image_validation_status"
DETAIL:  Failing row contains (1, 64, /static/generated/img_hf_1770403755.png',, null, ContentOrchestrationCrew, COMPLETED, 2026-02-07 00:17:28.507254).

[SQL: INSERT INTO image_contents (campaign_id, generated_image_url, prompt_used, agent_name, validation_status) VALUES (%(campaign_id)s, %(generated_image_url)s, %(prompt_used)s, %(agent_name)s, %(validation_status)s) RETURNING image_contents.image_id, image_contents.created_at]
[parameters: {'campaign_id': 64, 'generated_image_url': "/static/generated/img_hf_1770403755.png',", 'prompt_used': None, 'agent_name': 'ContentOrchestrationCrew', 'validation_status': 'COMPLETED'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2026-02-07 00:21:45 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 00:21:45 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 00:21:45 - src.routes.api_routes - INFO - [api_routes.py:391] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 00:21:45 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 00:21:45 - src.core.orchestrator - INFO - [orchestrator.py:203] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 00:21:45 - src.core.orchestrator - INFO - [orchestrator.py:206] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 00:21:45 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 00:21:45 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 00:21:45 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:21:47 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:21:47 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:22:14 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:22:14 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:22:15 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 00:22:15 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 00:22:20 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 00:22:20 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 00:22:20 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 00:22:20 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 00:22:20 - src.core.orchestrator - INFO - [orchestrator.py:203] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 00:22:20 - src.core.orchestrator - INFO - [orchestrator.py:206] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 00:22:20 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 00:22:20 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 00:22:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:22:23 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:22:23 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:22:53 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 00:22:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:22:55 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:22:55 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:23:25 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 00:23:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:23:25 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:23:26 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 00:23:26 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 00:23:26 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 00:23:27 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1397 characters in 813.75ms
2026-02-07 00:23:27 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:23:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:23:27 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-07 00:23:57 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 00:23:57 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:23:57 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:23:57 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 00:23:57 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 00:24:08 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770404047.png in 10.13s
2026-02-07 00:24:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:24:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:24:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:24:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:24:08 - src.core.orchestrator - INFO - [orchestrator.py:164] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 00:24:08 - src.core.orchestrator - INFO - [orchestrator.py:214] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 00:24:08 - src.core.orchestrator - INFO - [orchestrator.py:217] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 00:24:08 - src.routes.api_routes - ERROR - [api_routes.py:349] - _save_orchestration_results() - Failed to save results: (psycopg2.errors.CheckViolation) new row for relation "image_contents" violates check constraint "chk_image_validation_status"
DETAIL:  Failing row contains (2, 66, /static/generated/img_hf_1770404047.png, null, ContentOrchestrationCrew, APPROVED, 2026-02-07 00:22:20.897956).

[SQL: INSERT INTO image_contents (campaign_id, generated_image_url, prompt_used, agent_name, validation_status) VALUES (%(campaign_id)s, %(generated_image_url)s, %(prompt_used)s, %(agent_name)s, %(validation_status)s) RETURNING image_contents.image_id, image_contents.created_at]
[parameters: {'campaign_id': 66, 'generated_image_url': '/static/generated/img_hf_1770404047.png', 'prompt_used': None, 'agent_name': 'ContentOrchestrationCrew', 'validation_status': 'APPROVED'}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
2026-02-07 00:27:35 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:27:35 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 00:27:36 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 00:27:36 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 00:27:43 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 00:27:43 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 00:27:43 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 00:27:43 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 00:27:43 - src.core.orchestrator - INFO - [orchestrator.py:203] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 00:27:43 - src.core.orchestrator - INFO - [orchestrator.py:206] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 00:27:43 - src.core.orchestrator - INFO - [orchestrator.py:47] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 00:27:43 - src.core.orchestrator - INFO - [orchestrator.py:55] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 00:27:43 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:27:45 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:27:45 - src.core.orchestrator - INFO - [orchestrator.py:69] - run_campaign() -  Stage 1 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:28:15 - src.core.orchestrator - INFO - [orchestrator.py:73] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 00:28:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 00:28:18 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:28:18 - src.core.orchestrator - INFO - [orchestrator.py:89] - run_campaign() -  Stage 2 Complete. Sleeping to reset Rate Limits...
2026-02-07 00:28:48 - src.core.orchestrator - INFO - [orchestrator.py:107] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 00:28:48 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:28:48 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:28:49 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 00:28:49 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 00:28:49 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 00:28:50 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1133 characters in 789.07ms
2026-02-07 00:28:50 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:28:50 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:28:50 - src.core.orchestrator - INFO - [orchestrator.py:130] - run_campaign() -  Stage 3a Complete (Text Generated). Sleeping to reset Rate Limits...
2026-02-07 00:29:20 - src.core.orchestrator - INFO - [orchestrator.py:134] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 00:29:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:29:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:29:21 - src.core.hf_image_gen - INFO - [hf_image_gen.py:29] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 00:29:21 - src.core.hf_image_gen - INFO - [hf_image_gen.py:37] - generate() -  Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 00:29:31 - src.core.hf_image_gen - INFO - [hf_image_gen.py:57] - generate() -  Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770404371.png in 10.26s
2026-02-07 00:29:31 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 00:29:31 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 00:29:31 - src.core.orchestrator - INFO - [orchestrator.py:164] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 00:29:31 - src.core.orchestrator - INFO - [orchestrator.py:214] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 00:29:31 - src.core.orchestrator - INFO - [orchestrator.py:217] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.brand_validator - INFO - [brand_validator.py:73] - __init__() - BrandValidator initialized: 6 forbidden terms, 6 allowed phrases
2026-02-07 14:01:00 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:00 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:00 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 2.03ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-07 14:01:00 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:00 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.00ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-07 14:01:00 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:02 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: Replicate API Error
2026-02-07 14:01:02 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:02 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 2.56ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-07 14:01:02 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:02 - src.core.image_content_gen - ERROR - [image_content_gen.py:91] - generate() - Error generating image with Replicate: Replicate returned empty output.
2026-02-07 14:01:02 - src.core.image_content_gen - INFO - [image_content_gen.py:29] - __init__() - MLflow experiment set to: image_content_generation
2026-02-07 14:01:02 - src.core.image_content_gen - INFO - [image_content_gen.py:85] - generate() - Image generated successfully in 0.54ms: https://replicate.delivery/pbxt/mockimage123.webp
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Create marketing copy...'
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 41 characters in 1.01ms
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-70b-versatile
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test prompt...'
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 41 characters in 1.08ms
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test...'
2026-02-07 14:01:02 - src.core.text_content_gen - ERROR - [text_content_gen.py:106] - generate_text() - Text generation failed: Run with UUID 93d8c72451964db7a291173a25cc37c2 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 14:01:02 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Test...'
2026-02-07 14:01:02 - src.core.text_content_gen - ERROR - [text_content_gen.py:106] - generate_text() - Text generation failed: Run with UUID 93d8c72451964db7a291173a25cc37c2 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True
2026-02-07 15:12:44 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:12:44 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:12:44 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 15:12:45 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 15:13:03 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 15:13:03 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 15:13:03 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 15:13:03 - src.core.orchestrator - INFO - [orchestrator.py:195] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 15:13:03 - src.core.orchestrator - INFO - [orchestrator.py:196] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 15:13:03 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 15:13:03 - src.core.orchestrator - INFO - [orchestrator.py:49] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 15:13:03 - src.core.orchestrator - INFO - [orchestrator.py:66] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 15:13:03 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:13:05 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:13:05 - src.core.orchestrator - INFO - [orchestrator.py:79] - run_campaign() -  Stage 1 Complete.
2026-02-07 15:13:05 - src.core.orchestrator - INFO - [orchestrator.py:82] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 15:13:05 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:13:06 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:13:06 - src.core.orchestrator - INFO - [orchestrator.py:97] - run_campaign() -  Stage 2 Complete.
2026-02-07 15:13:06 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 15:13:06 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:13:06 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:13:07 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 15:13:07 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 15:13:07 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 15:13:08 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1448 characters in 854.00ms
2026-02-07 15:13:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:13:09 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:13:09 - src.core.orchestrator - INFO - [orchestrator.py:125] - run_campaign() -  Stage 3a Complete (Text Generated).
2026-02-07 15:13:09 - src.core.orchestrator - INFO - [orchestrator.py:128] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 15:13:09 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:13:09 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:13:09 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:13:09 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 15:13:20 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770457399.png in 10.49s
2026-02-07 15:13:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:13:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:13:20 - src.core.orchestrator - INFO - [orchestrator.py:157] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 15:13:20 - src.core.orchestrator - INFO - [orchestrator.py:207] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 15:13:20 - src.core.orchestrator - INFO - [orchestrator.py:210] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 15:31:02 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:31:02 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:31:02 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 15:31:02 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 15:31:08 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 15:31:08 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 15:31:08 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 15:31:08 - src.core.orchestrator - INFO - [orchestrator.py:186] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 15:31:08 - src.core.orchestrator - INFO - [orchestrator.py:187] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 15:31:08 - src.core.orchestrator - INFO - [orchestrator.py:190] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 15:31:08 - src.core.orchestrator - INFO - [orchestrator.py:49] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 15:31:08 - src.core.orchestrator - INFO - [orchestrator.py:66] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 15:31:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:31:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:31:10 - src.core.orchestrator - INFO - [orchestrator.py:79] - run_campaign() -  Stage 1 Complete.
2026-02-07 15:31:10 - src.core.orchestrator - INFO - [orchestrator.py:82] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 15:31:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:31:13 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:31:13 - src.core.orchestrator - INFO - [orchestrator.py:97] - run_campaign() -  Stage 2 Complete.
2026-02-07 15:31:13 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 15:31:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:31:13 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:31:13 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 15:31:13 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 15:31:13 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 15:31:14 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1405 characters in 864.02ms
2026-02-07 15:31:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:31:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:31:15 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_campaign() -  Stage 3a Complete (Text Generated).
2026-02-07 15:31:15 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 15:31:15 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:31:15 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:31:15 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:31:15 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 15:31:27 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770458487.png in 11.74s
2026-02-07 15:31:27 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:31:27 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:31:27 - src.core.orchestrator - INFO - [orchestrator.py:148] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 15:31:27 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 15:31:27 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 15:34:38 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:34:38 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:34:38 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 15:34:38 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 15:34:46 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 15:34:46 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 15:34:46 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 15:34:46 - src.core.orchestrator - INFO - [orchestrator.py:186] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 15:34:46 - src.core.orchestrator - INFO - [orchestrator.py:187] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 15:34:46 - src.core.orchestrator - INFO - [orchestrator.py:190] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 15:34:46 - src.core.orchestrator - INFO - [orchestrator.py:49] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 15:34:46 - src.core.orchestrator - INFO - [orchestrator.py:66] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 15:34:46 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:34:49 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:34:49 - src.core.orchestrator - INFO - [orchestrator.py:79] - run_campaign() -  Stage 1 Complete.
2026-02-07 15:34:49 - src.core.orchestrator - INFO - [orchestrator.py:82] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 15:34:49 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:34:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:34:51 - src.core.orchestrator - INFO - [orchestrator.py:97] - run_campaign() -  Stage 2 Complete.
2026-02-07 15:34:51 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 15:34:51 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:34:51 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:34:52 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 15:34:52 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 15:34:52 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 15:34:53 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1455 characters in 886.02ms
2026-02-07 15:34:53 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:34:53 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:34:53 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:34:53 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A group of diverse individuals from different age groups, backgrounds, and fitness levels participating in various wellness activities such as yoga, jogging, and meditation in a serene outdoor environment with a beautiful background of greenery and a clear blue sky.'...
2026-02-07 15:35:04 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770458704.png in 11.04s
2026-02-07 15:35:04 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:35:04 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:35:04 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_campaign() -  Stage 3a Complete (Text Generated).
2026-02-07 15:35:04 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 15:35:05 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:35:05 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:35:05 - src.core.orchestrator - INFO - [orchestrator.py:148] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 15:35:05 - src.core.orchestrator - INFO - [orchestrator.py:198] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 15:35:05 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 15:37:49 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:37:49 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:37:49 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 15:37:49 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 15:37:56 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 15:37:56 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 15:37:56 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=1)
2026-02-07 15:37:56 - src.core.orchestrator - INFO - [orchestrator.py:187] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'Test Gen Fix' (max attempts: 1)
2026-02-07 15:37:56 - src.core.orchestrator - INFO - [orchestrator.py:188] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 15:37:56 - src.core.orchestrator - INFO - [orchestrator.py:191] - run_with_auto_regeneration() -  Plan Generation Attempt 1/1 for campaign 'Test Gen Fix'
2026-02-07 15:37:56 - src.core.orchestrator - INFO - [orchestrator.py:49] - run_campaign() - Starting campaign orchestration: 'Test Gen Fix' for FitNow
2026-02-07 15:37:56 - src.core.orchestrator - INFO - [orchestrator.py:66] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 15:37:56 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:37:58 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:37:58 - src.core.orchestrator - INFO - [orchestrator.py:79] - run_campaign() -  Stage 1 Complete.
2026-02-07 15:37:58 - src.core.orchestrator - INFO - [orchestrator.py:82] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 15:37:58 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:38:00 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:38:00 - src.core.orchestrator - INFO - [orchestrator.py:97] - run_campaign() -  Stage 2 Complete.
2026-02-07 15:38:00 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 15:38:00 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:38:00 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:38:01 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 15:38:01 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 15:38:01 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 15:38:02 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1543 characters in 887.05ms
2026-02-07 15:38:02 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:38:02 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:38:02 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_campaign() -  Stage 3a Complete (Text Generated).
2026-02-07 15:38:02 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 15:38:02 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:38:02 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:38:02 - src.core.tools - INFO - [tools.py:29] - _run() - ImageGenerationTool called with prompt: A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.
2026-02-07 15:38:03 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:38:03 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 15:38:14 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770458894.png in 11.34s
2026-02-07 15:38:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:38:14 - src.core.orchestrator - WARNING - [orchestrator.py:53] - log_retry() -  Rate limit hit. Retrying attempt 1...
2026-02-07 15:38:19 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:38:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:38:20 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:38:20 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:38:20 - src.core.orchestrator - INFO - [orchestrator.py:149] - run_campaign() - Campaign 'Test Gen Fix' orchestration completed successfully
2026-02-07 15:38:20 - src.core.orchestrator - INFO - [orchestrator.py:199] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 15:38:20 - src.core.orchestrator - INFO - [orchestrator.py:202] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 15:39:07 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:39:07 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:39:07 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 15:39:07 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 15:39:13 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 15:39:13 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 15:39:13 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=1)
2026-02-07 15:39:13 - src.core.orchestrator - INFO - [orchestrator.py:189] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'Test Gen Fix' (max attempts: 1)
2026-02-07 15:39:13 - src.core.orchestrator - INFO - [orchestrator.py:190] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 15:39:13 - src.core.orchestrator - INFO - [orchestrator.py:193] - run_with_auto_regeneration() -  Plan Generation Attempt 1/1 for campaign 'Test Gen Fix'
2026-02-07 15:39:13 - src.core.orchestrator - INFO - [orchestrator.py:49] - run_campaign() - Starting campaign orchestration: 'Test Gen Fix' for FitNow
2026-02-07 15:39:13 - src.core.orchestrator - INFO - [orchestrator.py:66] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 15:39:13 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:39:14 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:14 - src.core.orchestrator - INFO - [orchestrator.py:79] - run_campaign() -  Stage 1 Complete.
2026-02-07 15:39:14 - src.core.orchestrator - INFO - [orchestrator.py:82] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 15:39:14 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:39:17 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:17 - src.core.orchestrator - INFO - [orchestrator.py:97] - run_campaign() -  Stage 2 Complete.
2026-02-07 15:39:17 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 15:39:17 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:39:17 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:18 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 15:39:18 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 15:39:18 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 15:39:19 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1284 characters in 726.28ms
2026-02-07 15:39:19 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:39:19 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:19 - src.core.tools - INFO - [tools.py:29] - _run() - ImageGenerationTool called with prompt: A group of diverse people from different ages and backgrounds exercising together in a park, with a subtle background of the FitNow logo and the tagline 'Transform Your Tomorrow, Today'.
2026-02-07 15:39:19 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:39:19 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A group of diverse people from different ages and backgrounds exercising together in a park, with a subtle background of the FitNow logo and the tagline 'Transform Your Tomorrow, Today'.'...
2026-02-07 15:39:30 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770458970.png in 10.81s
2026-02-07 15:39:30 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:39:30 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:30 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'The social media post should be short and catchy, ...'
2026-02-07 15:39:31 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 745 characters in 503.97ms
2026-02-07 15:39:31 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:39:31 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:31 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_campaign() -  Stage 3a Complete (Text Generated).
2026-02-07 15:39:31 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 15:39:31 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:39:32 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:32 - src.core.tools - INFO - [tools.py:29] - _run() - ImageGenerationTool called with prompt: A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.
2026-02-07 15:39:32 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:39:32 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 15:39:42 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770458982.png in 10.48s
2026-02-07 15:39:42 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:39:42 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:39:42 - src.core.orchestrator - INFO - [orchestrator.py:151] - run_campaign() - Campaign 'Test Gen Fix' orchestration completed successfully
2026-02-07 15:39:42 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 15:39:42 - src.core.orchestrator - INFO - [orchestrator.py:204] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
2026-02-07 15:42:58 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGTERM handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:42:58 - crewai.telemetry.telemetry - WARNING - [telemetry.py:216] - _register_signal_handler() - Cannot register SIGINT handler: not running in main thread
Traceback (most recent call last):
  File "E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\venv\Lib\site-packages\crewai\telemetry\telemetry.py", line 214, in _register_signal_handler
    signal.signal(sig, handler)
  File "C:\Python311\Lib\signal.py", line 56, in signal
    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: signal only works in main thread of the main interpreter
2026-02-07 15:42:59 - faiss.loader - INFO - [loader.py:132] - <module>() - Loading faiss with AVX2 support.
2026-02-07 15:42:59 - faiss.loader - INFO - [loader.py:134] - <module>() - Successfully loaded faiss with AVX2 support.
2026-02-07 15:43:06 - src.core.orchestrator - INFO - [orchestrator.py:15] - __init__() - Initializing ContentOrchestrationCrew...
2026-02-07 15:43:06 - src.core.orchestrator - DEBUG - [orchestrator.py:28] - __init__() - Configured Groq API (key: gsk_Vv7zsWXPkQg...)
2026-02-07 15:43:06 - src.routes.api_routes - INFO - [api_routes.py:393] - orchestrate_campaign() - Running campaign with auto-regeneration (max_attempts=3)
2026-02-07 15:43:06 - src.core.orchestrator - INFO - [orchestrator.py:189] - run_with_auto_regeneration() - Starting auto-regeneration workflow for 'FitNow New Year Wellness Journey' (max attempts: 3)
2026-02-07 15:43:06 - src.core.orchestrator - INFO - [orchestrator.py:190] - run_with_auto_regeneration() - Workflow: RAG  Plan  Validate PLAN  (approved) Generate Content | (rejected) Regenerate Plan
2026-02-07 15:43:06 - src.core.orchestrator - INFO - [orchestrator.py:193] - run_with_auto_regeneration() -  Plan Generation Attempt 1/3 for campaign 'FitNow New Year Wellness Journey'
2026-02-07 15:43:06 - src.core.orchestrator - INFO - [orchestrator.py:49] - run_campaign() - Starting campaign orchestration: 'FitNow New Year Wellness Journey' for FitNow
2026-02-07 15:43:06 - src.core.orchestrator - INFO - [orchestrator.py:66] - run_campaign() -  STAGE 1: Planning Strategy...
2026-02-07 15:43:06 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:43:08 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:43:08 - src.core.orchestrator - INFO - [orchestrator.py:79] - run_campaign() -  Stage 1 Complete.
2026-02-07 15:43:08 - src.core.orchestrator - INFO - [orchestrator.py:82] - run_campaign() -  STAGE 2: Validating Plan...
2026-02-07 15:43:08 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.3-70b-versatile; provider = groq
2026-02-07 15:43:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:43:10 - src.core.orchestrator - INFO - [orchestrator.py:97] - run_campaign() -  Stage 2 Complete.
2026-02-07 15:43:10 - src.core.orchestrator - INFO - [orchestrator.py:103] - run_campaign() -  STAGE 3a: Generating Text Content...
2026-02-07 15:43:10 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:43:10 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:43:11 - src.core.text_content_gen - INFO - [text_content_gen.py:42] - __init__() - MLflow experiment set to: text_content_generation
2026-02-07 15:43:11 - src.core.text_content_gen - INFO - [text_content_gen.py:46] - __init__() - Initialized TextGenerator with Groq model: llama-3.1-8b-instant
2026-02-07 15:43:11 - src.core.text_content_gen - INFO - [text_content_gen.py:69] - generate_text() - Generating text for prompt: 'Write compelling marketing copy for the FitNow New...'
2026-02-07 15:43:12 - src.core.text_content_gen - INFO - [text_content_gen.py:101] - generate_text() - Successfully generated 1202 characters in 927.69ms
2026-02-07 15:43:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:43:12 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:43:12 - src.core.orchestrator - INFO - [orchestrator.py:124] - run_campaign() -  Stage 3a Complete (Text Generated).
2026-02-07 15:43:12 - src.core.orchestrator - INFO - [orchestrator.py:127] - run_campaign() -  STAGE 3b: Generating Image...
2026-02-07 15:43:12 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:43:13 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:43:13 - src.core.tools - INFO - [tools.py:29] - _run() - ImageGenerationTool called with prompt: A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.
2026-02-07 15:43:13 - src.core.hf_image_gen - INFO - [hf_image_gen.py:28] - __init__() - Initialized HuggingFaceGenerator with model: stabilityai/stable-diffusion-xl-base-1.0
2026-02-07 15:43:13 - src.core.hf_image_gen - INFO - [hf_image_gen.py:36] - generate() - Generating image via Hugging Face: 'A serene wellness scene with a person in athletic wear meditating outdoors at sunrise, surrounded by nature. Calming blue and white tones. Modern, inspiring aesthetic.'...
2026-02-07 15:43:25 - src.core.hf_image_gen - INFO - [hf_image_gen.py:56] - generate() - Image saved to E:\WORK\BridgeLabz\Agentic_CX_Content_Studio\static\generated\img_hf_1770459205.png in 12.15s
2026-02-07 15:43:25 - LiteLLM - INFO - [utils.py:3887] - _check_valid_arg() - 
LiteLLM completion() model= llama-3.1-8b-instant; provider = groq
2026-02-07 15:43:26 - LiteLLM - INFO - [utils.py:1629] - wrapper() - Wrapper: Completed Call, calling success_handler
2026-02-07 15:43:26 - src.core.orchestrator - INFO - [orchestrator.py:151] - run_campaign() - Campaign 'FitNow New Year Wellness Journey' orchestration completed successfully
2026-02-07 15:43:26 - src.core.orchestrator - INFO - [orchestrator.py:201] - run_with_auto_regeneration() - Plan Validation Status: approved
2026-02-07 15:43:26 - src.core.orchestrator - INFO - [orchestrator.py:204] - run_with_auto_regeneration() -  Campaign plan approved on attempt 1. Content generated successfully.
